# Stat Stress Testing & Efficiency Analysis Plan

**Date:** 2025-12-04 (Updated)  
**Purpose:** Round-Robin stat efficiency testing via Monte Carlo simulation  
**Status:** Implementation In Progress

---

## üéØ OBJECTIVE

Create a **deterministic, dynamic stress-testing system** that measures **relative stat efficiency** through Round-Robin matchups:

1. **Mono-Stat Archetypes**: Generate configs with +N points in ONE stat (weighted by current weight)
2. **Round-Robin Testing**: Each stat@budget vs every other stat@budget (NxN matrix)
3. **Efficiency Scoring**: Calculate empirical efficiency of each stat from win rates
4. **Multi-Tier Analysis**: Test at multiple budget tiers (25, 50, 75 points)
5. **Dynamic Generation**: Read stats from live BalancerConfig (no hardcoding, no derived stats)
6. **Presentation**: Efficiency table + NxN heatmap + radar chart

---

## üß† METHODOLOGY (Correct Approach)

### Why Round-Robin > Baseline Testing

‚ùå **Old approach (stat vs baseline)**: Not sufficient ‚Äî doesn't compare stats against each other  
‚úÖ **Correct approach (stat@N vs stat@N)**: Round-robin produces relative efficiency

### How It Works

For each stat pair (A, B):
- Archetype A: baseline + (weightA √ó budget) on statA
- Archetype B: baseline + (weightB √ó budget) on statB
- Run 500‚Äì1000 Monte Carlo simulations (seeded RNG)
- Record winRateA (winRateB = 1 - winRateA)

This creates an **NxN matrix** where each cell = efficiency of statA vs statB at same budget.

### Efficiency Calculation

```
efficiency(statX) = mean(winRate of X@budget vs Y@budget for all Y ‚â† X)
```

Example:
| Stat | Efficiency |
|------|------------|
| ATK  | 68%        |
| SPD  | 59%        |
| CRIT | 52%        |
| HP   | 44%        |
| ARMOR| 33%        |

**Interpretation:**
- ATK too strong ‚Üí increase weight/cost
- ARMOR too weak ‚Üí decrease weight/cost

### Multi-Tier Testing

Test at multiple budgets to detect non-linear scaling:
- Tier 1: +25 points
- Tier 2: +50 points  
- Tier 3: +75 points

If HP@25 is weak but HP@75 is OP ‚Üí non-linear scaling issue ‚Üí fix formula.

### Additional Metrics

Beyond win rate, track:
- **avgTurns**: burst stat (low) vs sustain stat (high)
- **hpRemaining**: defensive efficiency
- **damageDealt**: offensive efficiency

---

## üìã PHASE 1: Archetype Generation Engine

### 1.1 Mono-Stat Archetypes (Dynamic from BalancerConfig)

**Goal:** For each non-derived stat in the live BalancerConfig, create an archetype that stresses it.

**Source:** Stats come from `BalancerConfig.stats` (the same config used by the Balancer tab).

**Filtering:**
- Exclude `isDerived === true`
- Exclude stats with `formula` field
- Exclude `isHidden === true`

```typescript
// File: src/balancing/testing/StressTestArchetypeGenerator.ts

interface StatsArchetype {
  id: string;
  name: string;
  type: 'single-stat';
  stats: StatBlock;           // Full stat block for simulation
  testedStats: string[];      // [statId]
  pointsPerStat: number;      // Budget tier (25, 50, 75)
  weights: Record<string, number>;
  description: string;
}

class StatsArchetypeGenerator {
  private readonly config: BalancerConfig;
  private readonly nonDerivedStatIds: string[];

  constructor(config: BalancerConfig) {
    this.config = config;
    // Filter: only non-derived, non-formula, non-hidden stats
    this.nonDerivedStatIds = Object.values(config.stats)
      .filter((s) => !s.isDerived && !s.formula && !s.isHidden)
      .map((s) => s.id);
  }

  generateSingleStatArchetypes(pointTiers: number[] = [25, 50, 75]): StatsArchetype[] {
    const result: StatsArchetype[] = [];

    for (const statId of this.nonDerivedStatIds) {
      const def = this.config.stats[statId];
      if (!def) continue;

      for (const pointsPerStat of pointTiers) {
        // Use weight from config (live from Balancer tab)
        const weight = def.weight;
        const delta = weight * pointsPerStat;

        const stats = cloneBaseline();
        stats[statId] = (stats[statId] ?? 0) + delta;

        result.push({
          id: `stress-${statId}-${pointsPerStat}`,
          name: `Stress +${pointsPerStat} ${def.label}`,
          type: 'single-stat',
          stats,
          testedStats: [statId],
          pointsPerStat,
          weights: { [statId]: weight },
          description: `Baseline + ${delta.toFixed(2)} (${weight} hp/pt √ó ${pointsPerStat} pt) on ${def.label}`,
        });
      }
    }

    return result;
  }
}
```

---

## üìä PHASE 2: Round-Robin Simulation Engine

### 2.1 Round-Robin Runner

The core of the system: run every stat@budget vs every other stat@budget.

```typescript
// File: src/balancing/testing/RoundRobinRunner.ts

interface MatchupResult {
  statA: string;
  statB: string;
  pointsPerStat: number;
  winRateA: number;      // Win rate of statA archetype
  winRateB: number;      // = 1 - winRateA
  avgTurns: number;
  iterations: number;
}

interface StatEfficiency {
  statId: string;
  pointsPerStat: number;
  efficiency: number;    // Mean win rate vs all other stats
  wins: number;          // Total matchups won (winRate > 0.5)
  losses: number;        // Total matchups lost
  matchups: MatchupResult[];
}

class RoundRobinRunner {
  constructor(private config: BalancerConfig) {}

  /**
   * Run full round-robin for a given budget tier.
   * Returns NxN matchup matrix + per-stat efficiency scores.
   */
  async runRoundRobin(
    archetypes: StatsArchetype[],
    iterations: number = 1000
  ): Promise<{
    matchups: MatchupResult[];
    efficiencies: StatEfficiency[];
  }> {
    const matchups: MatchupResult[] = [];

    // For each pair (i, j) where i < j
    for (let i = 0; i < archetypes.length; i++) {
      for (let j = i + 1; j < archetypes.length; j++) {
        const archA = archetypes[i];
        const archB = archetypes[j];

        // Run Monte Carlo: archA vs archB
        const result = MonteCarloSimulation.run({
          combat: {
            entity1: toEntityStats(archA.stats, archA.testedStats[0]),
            entity2: toEntityStats(archB.stats, archB.testedStats[0]),
            turnLimit: 100,
          },
          iterations,
        });

        matchups.push({
          statA: archA.testedStats[0],
          statB: archB.testedStats[0],
          pointsPerStat: archA.pointsPerStat,
          winRateA: result.summary.winRates.entity1,
          winRateB: result.summary.winRates.entity2,
          avgTurns: result.combatStatistics.averageTurns,
          iterations,
        });
      }
    }

    // Calculate efficiency for each stat
    const efficiencies = this.calculateEfficiencies(archetypes, matchups);

    return { matchups, efficiencies };
  }

  private calculateEfficiencies(
    archetypes: StatsArchetype[],
    matchups: MatchupResult[]
  ): StatEfficiency[] {
    const statIds = archetypes.map((a) => a.testedStats[0]);
    const pointsPerStat = archetypes[0]?.pointsPerStat ?? 25;

    return statIds.map((statId) => {
      // Find all matchups involving this stat
      const relevant = matchups.filter(
        (m) => m.statA === statId || m.statB === statId
      );

      // Calculate win rates from this stat's perspective
      const winRates = relevant.map((m) =>
        m.statA === statId ? m.winRateA : m.winRateB
      );

      const efficiency = winRates.reduce((a, b) => a + b, 0) / winRates.length;
      const wins = winRates.filter((wr) => wr > 0.5).length;
      const losses = winRates.filter((wr) => wr < 0.5).length;

      return {
        statId,
        pointsPerStat,
        efficiency,
        wins,
        losses,
        matchups: relevant,
      };
    });
  }
}
```

### 2.2 Metrics Types

```typescript
// File: src/balancing/testing/metrics.ts

interface StatEfficiencyMetrics {
  statId: string;
  pointsPerStat: number;
  efficiency: number;        // 0‚Äì1, mean win rate vs all others
  rank: number;              // 1 = strongest
  assessment: 'OP' | 'strong' | 'balanced' | 'weak' | 'underpowered';
}

// Assessment thresholds:
// efficiency > 0.65 ‚Üí OP (needs nerf / higher cost)
// efficiency > 0.55 ‚Üí strong
// efficiency 0.45‚Äì0.55 ‚Üí balanced
// efficiency 0.35‚Äì0.45 ‚Üí weak
// efficiency < 0.35 ‚Üí underpowered (needs buff / lower cost)
```

---

## üé® PHASE 3: Presentation Layer (‚úÖ Core Implemented)

### 3.1 Stat Efficiency Table

Shows per-stat efficiency scores ranked from strongest to weakest.

```typescript
// File: src/ui/testing/StatEfficiencyTable.tsx

interface StatEfficiencyTableProps {
  efficiencies: StatEfficiency[];
  tier: number;
}

export const StatEfficiencyTable: React.FC<StatEfficiencyTableProps> = ({
  efficiencies,
  tier
}) => {
  const sorted = [...efficiencies].sort((a, b) => b.efficiency - a.efficiency);
  
  const getAssessment = (eff: number) => {
    if (eff > 0.65) return { label: 'OP', color: 'text-red-400' };
    if (eff > 0.55) return { label: 'Strong', color: 'text-amber-400' };
    if (eff > 0.45) return { label: 'Balanced', color: 'text-green-400' };
    if (eff > 0.35) return { label: 'Weak', color: 'text-blue-400' };
    return { label: 'Underpowered', color: 'text-purple-400' };
  };
  
  return (
    <table className="w-full text-sm">
      <thead>
        <tr className="border-b border-indigo-500/30">
          <th className="px-3 py-2 text-left">Rank</th>
          <th className="px-3 py-2 text-left">Stat</th>
          <th className="px-3 py-2 text-right">Efficiency</th>
          <th className="px-3 py-2 text-right">W/L</th>
          <th className="px-3 py-2 text-center">Assessment</th>
        </tr>
      </thead>
      <tbody>
        {sorted.map((eff, idx) => {
          const assessment = getAssessment(eff.efficiency);
          return (
            <tr key={eff.statId} className="border-b border-slate-700/50">
              <td className="px-3 py-2 text-slate-400">#{idx + 1}</td>
              <td className="px-3 py-2 font-semibold text-indigo-300">{eff.statId}</td>
              <td className="px-3 py-2 text-right font-mono">
                {(eff.efficiency * 100).toFixed(1)}%
              </td>
              <td className="px-3 py-2 text-right text-slate-400">
                {eff.wins}W / {eff.losses}L
              </td>
              <td className={`px-3 py-2 text-center ${assessment.color}`}>
                {assessment.label}
              </td>
            </tr>
          );
        })}
      </tbody>
    </table>
  );
};
```

### 3.2 NxN Matchup Heatmap

Shows win rates for every stat vs every other stat.

```typescript
// File: src/ui/testing/MatchupHeatmap.tsx

interface MatchupHeatmapProps {
  matchups: MatchupResult[];
  statIds: string[];
}

export const MatchupHeatmap: React.FC<MatchupHeatmapProps> = ({ matchups, statIds }) => {
  // Build NxN matrix
  const matrix: Record<string, Record<string, number>> = {};
  
  statIds.forEach(s => {
    matrix[s] = {};
    statIds.forEach(s2 => {
      matrix[s][s2] = 0.5; // Default = draw
    });
  });
  
  matchups.forEach(m => {
    matrix[m.statA][m.statB] = m.winRateA;
    matrix[m.statB][m.statA] = m.winRateB;
  });
  
  const getColor = (winRate: number) => {
    if (winRate > 0.7) return 'bg-green-600';
    if (winRate > 0.55) return 'bg-green-500/60';
    if (winRate > 0.45) return 'bg-slate-600';
    if (winRate > 0.3) return 'bg-red-500/60';
    return 'bg-red-600';
  };
  
  return (
    <div className="overflow-x-auto">
      <table className="border-collapse text-xs">
        <thead>
          <tr>
            <th className="px-2 py-1 text-slate-400">vs</th>
            {statIds.map(s => (
              <th key={s} className="px-2 py-1 text-indigo-200 font-semibold">
                {s}
              </th>
            ))}
          </tr>
        </thead>
        <tbody>
          {statIds.map(statA => (
            <tr key={statA}>
              <th className="px-2 py-1 text-indigo-200 font-semibold text-right">
                {statA}
              </th>
              {statIds.map(statB => {
                const winRate = matrix[statA][statB];
                const isSelf = statA === statB;
                return (
                  <td 
                    key={`${statA}-${statB}`}
                    className={`px-2 py-1 ${isSelf ? 'bg-slate-800' : getColor(winRate)} text-white text-center`}
                    title={`${statA} vs ${statB}: ${(winRate * 100).toFixed(0)}%`}
                  >
                    {isSelf ? '‚Äî' : (winRate * 100).toFixed(0)}
                  </td>
                );
              })}
            </tr>
          ))}
        </tbody>
      </table>
    </div>
  );
};
```

### 3.3 Efficiency Radar Chart

Visual representation of stat balance.

```typescript
// File: src/ui/testing/EfficiencyRadar.tsx

interface EfficiencyRadarProps {
  efficiencies: StatEfficiency[];
}

// SVG radar showing efficiency per stat
// Balanced = circular shape
// Imbalanced = spiky shape
```

---

## üîÑ PHASE 4: Integration (‚úÖ Round-Robin + Balancer Config Wiring)

### 4.1 Hook for Round-Robin Testing

```typescript
// File: src/ui/testing/useRoundRobinTesting.ts

export function useRoundRobinTesting() {
  const { config } = useBalancerConfig();
  const [results, setResults] = useState<RoundRobinResults | null>(null);
  const [isRunning, setIsRunning] = useState(false);

  const runTests = useCallback(async (tier: number = 25, iterations: number = 1000) => {
    setIsRunning(true);
    try {
      const generator = new StatsArchetypeGenerator(config);
      const archetypes = generator.generateSingleStatArchetypes([tier]);
      
      const runner = new RoundRobinRunner(config);
      const results = await runner.runRoundRobin(archetypes, iterations);
      
      setResults(results);
    } finally {
      setIsRunning(false);
    }
  }, [config]);

  return { results, isRunning, runTests };
}
```

### 4.2 Live Config Integration

- Stats come from `useBalancerConfig()` (live from Balancer tab)
- Weights come from `config.stats[statId].weight`
- Changes in Balancer tab reflect immediately in Stat Testing
- The **Stat Stress Testing** page now exposes a live, editable view of all non-derived stat weights, wired directly to `updateStat` on the shared `BalancerConfig`.

---

## üìà PHASE 5: Dashboard Page (‚úÖ First Iteration Shipped)

```typescript
// File: src/ui/testing/StatStressTestingPage.tsx

// Before run: show list of stats from current config
// After run: show efficiency table + NxN heatmap + radar
// Tier selector: 25 / 50 / 75
// Iterations selector: 500 / 1000 / 2000

// NEW (Dec 2025):
// - After results are available, show a clear table of current stat WEIGHTS
//   (config.stats[statId].weight) alongside the efficiency metrics.
// - Each weight must be editable in-place from this page.
// - Edits must propagate back through the shared config/store
//   (useBalancerConfig / BalancerConfigStore), so that:
//   - future stress-test runs use the updated weights
//   - any other system depending on weights (e.g. archetype generation)
//     sees the new values immediately.
```

---

## ‚úÖ SUCCESS CRITERIA

- [ ] Mono-stat archetypes generated dynamically from BalancerConfig
- [ ] Round-robin: every stat@N vs every other stat@N
- [ ] NxN matchup matrix with win rates
- [ ] Per-stat efficiency scores calculated
- [ ] Efficiency table with rank + assessment
- [ ] NxN heatmap visualization
- [ ] Multi-tier support (25, 50, 75)
- [ ] Deterministic (seeded RNG)
- [ ] Live integration with Balancer config

---

## üîó REFERENCES

**Related Documents:**
- `docs/plans/archetype_balancing_plan.md` - Archetype system
- `docs/STAT_BALANCING_ANALYSIS.md` - Weight calibration methodology
- `docs/plans/config_driven_balancer_plan.md` - Config system

**Key Files:**
- `src/balancing/testing/StressTestArchetypeGenerator.ts` ‚úÖ
- `src/balancing/testing/RoundRobinRunner.ts` (NEW)
- `src/balancing/testing/metrics.ts` ‚úÖ
- `src/ui/testing/StatEfficiencyTable.tsx` (NEW)
- `src/ui/testing/MatchupHeatmap.tsx` (NEW)
- `src/ui/testing/StatStressTestingPage.tsx` ‚úÖ

---

## üöÄ IMPLEMENTATION ROADMAP

### Step 1: Archetype Generator ‚úÖ
- Read stats from BalancerConfig
- Filter: no derived, no formula, no hidden
- Generate mono-stat archetypes at multiple tiers

### Step 2: Round-Robin Runner (‚úÖ Implemented)
- For each pair (statA, statB): run Monte Carlo
- Collect NxN matchup results
- Calculate per-stat efficiency

### Step 3: UI Components (‚úÖ First Pass Implemented)
- StatEfficiencyTable: ranked list with assessment
- MatchupHeatmap: NxN win rate matrix
- EfficiencyRadar: visual balance indicator

### Step 4: Integration (‚úÖ Config-Driven, Multi-Tier)
- Connected to live BalancerConfig via `useBalancerConfig`
- Tier selector (25 / 50 / 75 / 100) and iteration selector (500 / 1000 / 2000)
- Basic loading state and progress indication for long runs

---

## üß≠ PHASE 9: Auto Stat Balancer & History (Design)

> Goal: extend the existing stat stress testing system into a **config-driven Auto Stat Balancer** that can iteratively adjust `BalancerConfig.stats[*].weight` based on Round-Robin results, while keeping a structured history of runs and sessions.

### 9.1 High-Level Objectives

1. **Stat-Centric AutoBalance**
   - Use empirical Round-Robin efficiency scores (Section 2) as the primary signal to adjust stat weights.
   - Keep `BalancerConfig` as the **single source of truth** for all weights (no parallel tables, no hardcoding).

2. **Inline Weight Suggestions**
   - On the Stat Stress Testing UI, show **per-stat suggestions** (from a pure TS service) alongside the live weight inputs.
   - Suggestions must be **explainable** ("HP efficiency 0.62 > 0.55 ‚Üí nerf weight by ~10%") and bounded (per-iteration caps).

3. **History of Runs & Sessions**
   - Persist a dedicated `StatBalanceRun` history separate from the generic BalancerConfig history snapshots.
   - Each run stores: timestamp, tiers/iterations, a balance score, and a compact snapshot of efficiency metrics.
   - Group runs into `StatBalanceSession` when using AutoBalance (Section 9.4).

4. **Recursive AutoBalance Loop**
   - Implement an offline/authoring-only loop that:
     1. Reads current `BalancerConfig` weights.
     2. Runs Round-Robin tests for the configured tiers.
     3. Produces adjusted weights via a deterministic rule set.
     4. Persists both the new config and the run metrics as a session iteration.
   - Stop criteria: all stats in a target band (e.g. 0.45‚Äì0.55) and/or max iteration count.

5. **Historical Comparison Views**
   - Allow comparing multiple runs side-by-side (weights, efficiency scores, heatmaps) to understand the trajectory of changes.
   - Keep the UI read-only for historical data; edits happen only on the **current** BalancerConfig.

---

### 9.2 Domain Model (Stat AutoBalance)

New domain types (pure TS, no React):

- `StatBalanceRun`
  - `id: string`
  - `timestamp: number`
  - `configVersion: string`
  - `weights: Record<string, number>` (snapshot of non-derived stat weights)
  - `tiers: number[]` (e.g. [25, 50, 75, 100])
  - `iterationsPerTier: number`
  - `balanceScore: number` (aggregate metric, e.g. mean |efficiency-0.5|)
  - `summary: { overpowered: string[]; underpowered: string[] }`

- `StatBalanceSession`
  - `sessionId: string`
  - `startTime: number`
  - `endTime?: number`
  - `runs: StatBalanceRun[]`
  - `strategy: 'manual' | 'auto'`

These types live under `src/balancing/testing` (or an adjacent `stats` subfolder) and are **UI-agnostic**.

---

### 9.3 Stat Weight Advisor (Suggestions Engine)

**Purpose:** Given a snapshot of Round-Robin stat efficiencies and the current `BalancerConfig`, propose **bounded weight adjustments** per stat.

Design sketch:

- File: `src/balancing/stats/StatWeightAdvisor.ts`
- Input:
  - `config: BalancerConfig`
  - `efficiencies: StatEfficiency[]` (from RoundRobinRunner, Section 2)
  - parameters: `targetBand = [0.45, 0.55]`, `maxDeltaPerIteration`, etc. (config-driven)
- Output (per stat):
  - `currentWeight: number`
  - `suggestedWeight: number`
  - `delta: number`
  - `reason: string`

Rules (example, tunable via config):

- If `efficiency > targetMax` ‚Üí stat is too strong ‚Üí **decrease** weight.
- If `efficiency < targetMin` ‚Üí stat is too weak ‚Üí **increase** weight.
- Clamp `|delta| / currentWeight <= maxRelativeDelta` (e.g. 10% per iteration).
- For derived/hidden stats: **no suggestions**.

The advisor is a **pure function**, testable via Vitest, and does not touch React or localStorage directly.

---

### 9.4 AutoBalance Session Engine

**Purpose:** Run multiple advisor iterations in a row, each time re-running Round-Robin on the updated config, to converge towards a balanced band.

Design sketch:

- File: `src/balancing/stats/AutoStatBalancer.ts`
- Core API:
  - `runSession(config: BalancerConfig, options): StatBalanceSession`
    - internally:
      1. For `i` in `[1..maxIterations]`:
         - run Round-Robin tests (using `RoundRobinRunner`),
         - compute `StatWeightAdvisor` suggestions,
         - apply suggestions to get `nextConfig`,
         - record a `StatBalanceRun`,
         - stop if all stats within target band.
      2. Return `StatBalanceSession` with all runs.

**Important:**

- The engine **returns** the resulting config + session, but **does not** persist anything by itself.
- Persistence is delegated to a dedicated store (Section 9.5) or to the caller (UI, CLI, etc.).

---

### 9.5 History Store (StatBalanceHistoryStore)

**Purpose:** Persist and query `StatBalanceRun` and `StatBalanceSession` data separately from BalancerConfig snapshots.

Design sketch:

- File: `src/balancing/stats/StatBalanceHistoryStore.ts`
- Backed by localStorage (or the same storage layer used by BalancerConfig), keys separated from `rpg_balancer_config`.
- API examples:
  - `addRun(run: StatBalanceRun): void`
  - `addSession(session: StatBalanceSession): void`
  - `listRuns(): StatBalanceRun[]`
  - `listSessions(): StatBalanceSession[]`
  - `getSession(id: string): StatBalanceSession | undefined`
  - `clear(): void`

No UI code here; only data access and validation.

---

### 9.6 UI Integration (Stat Stress Testing Page)

Key UX requirements for the **StatStressTestingPage**:

1. **Inline Suggestions Panel**
   - Extend the existing ‚ÄúStat Weights (Live)‚Äù card with an additional column for **suggested weights** and a short reason.
   - Per-row controls:
     - ‚ÄúApply‚Äù button ‚Üí applies suggestion for that single stat via `updateStat`.
   - Global controls:
     - ‚ÄúApply All Safe Suggestions‚Äù ‚Üí applies only suggestions with small deltas (within a configured threshold).

2. **AutoBalance Trigger (Optional, Phase 2)**
   - Add an ‚ÄúAutoBalance Session‚Äù CTA:
     - opens a modal / drawer with options (max iterations, tiers, thresholds),
     - triggers `AutoStatBalancer.runSession`,
     - once completed, offers to apply the final weights to `BalancerConfig`.

3. **History & Comparison (Read-Only)**
   - A secondary view/tab that lists historical `StatBalanceRun` and `StatBalanceSession`:
     - click on a run ‚Üí show its efficiency table, radar and heatmap (read-only snapshot).
     - multi-select ‚Üí compare 2-3 runs side-by-side (weights + key metrics).

These UI additions must remain **config-driven** (no hardcoded stat lists) and reuse existing components wherever possible.

---

### 9.7 Testing & Determinism

- All new services (`StatWeightAdvisor`, `AutoStatBalancer`, `StatBalanceHistoryStore`) must be covered by Vitest.
- Round-Robin invocations inside AutoBalance must:
  - use deterministic RNG seeds,
  - explicitly specify iterations per tier.
- Target: given the same starting `BalancerConfig` and options, the AutoBalance session should be reproducible.


---

## üßÆ PHASE 6: Simulation-Driven Point Valuation (Stat Costs)

> Goal: turn the empirical Round-Robin results into a **point cost per stat unit**, so the system can automatically price stats instead of using only hand-tuned weights.

### 6.1 Concept

- Each primary stat `X` gets a **point cost** `C(X)` that reflects how much it moves win rate when increased by a small amount.
- Instead of guessing `C(X)` manually, we **measure** it via Monte Carlo:
  1. Start from a **baseline build** (coming from BalancerConfig default values).
  2. Create a variant with `X` increased by `ŒîX` (e.g. `+10%` or `+5` flat).
  3. Run many self-play simulations (baseline vs boosted) to estimate **Œî win rate**.
  4. Convert that **Œî win rate** into a normalized **point cost** for `X`.

This is analogous to **sensitivity analysis** / **simulation balancing** in the literature: parameters that strongly affect win rate get a higher point cost.

### 6.2 Proposed Metric

For each stat `X`:

1. Define a reference delta `ŒîX` (per stat type):
   - HP: +50
   - Damage: +5
   - Armor: +5
   - CritChance: +5%
   - etc. (config-driven)
2. Run `N` Monte Carlo matches (seeded) between:
   - Entity A: baseline stats.
   - Entity B: baseline stats with `X += ŒîX`.
3. Measure `winRateBoosted` (win rate of Entity B vs A).
4. Define **marginal value** of X as:

```text
ŒîWR(X) = winRateBoosted - 0.5        // in [-0.5, +0.5]
```

5. Convert to **point cost per unit of X**:

```text
pointsPerUnit(X) = K * (ŒîWR(X) / targetDeltaWR) / ŒîX
```

Where:

- `targetDeltaWR` is a design target (e.g. `+0.05` = +5% win rate for the reference delta should correspond to 1 point).
- `K` is a global scaling constant to keep point values in a comfortable range.

### 6.3 Implementation Sketch (TODO)

New module, e.g. `src/balancing/testing/StatPointValuation.ts`:

- Input:
  - `BalancerConfig` (live stats definitions and default values).
  - Simulation parameters (iterations, seeds).
- Output:
  - `pointCosts: Record<string, number>` mapping `statId -> pointsPerUnit`.

Pipeline:

1. Build baseline `StatBlock` from BalancerConfig (same baseline used by `StressTestArchetypeGenerator`).
2. For each **non-derived** stat:
   - Construct `(baseline, baseline+ŒîX)` pair and run simulations.
   - Estimate `ŒîWR(X)` and `pointsPerUnit(X)`.
3. Persist results either:
   - Back into `config.stats[statId].weight` (overwriting manual weight), **or**
   - In a separate `pointCosts` structure consumed by archetype builders and other systems.

### 6.4 Current Status

- ‚úÖ We already have a robust **simulation engine** and Round-Robin framework (single-stat archetypes, Monte Carlo, win rates).
- ‚úÖ `metrics.ts` defines types that can be extended to store `ŒîWR` and related sensitivity info.
- ‚ùå We do **not yet** run dedicated simulations of `baseline vs baseline+ŒîX` per stat.
- ‚ùå There is **no module** that converts `Œî win rate` into a stable `pointsPerUnit` function.

---

## üîó PHASE 7: Synergy Function S(A, B) from Pair-Stat Simulations

> Goal: detect when **two stats together** are worth more than the sum of their individual contributions (non-linear synergy) and encode this as a synergy factor `S(A,B)` used in cost calculations.

### 7.1 Concept

For two stats A and B, we want to estimate how powerful **A+B together** are compared to what we would **expect** from A and B individually.

Terminology:

- `C(A)`, `C(B)`: individual point costs from Phase 6.
- `S(A,B)`: synergy factor.
- Combined cost:

```text
Cost(A+B) = C(A) + C(B) + S(A,B)
```

Synergy is **measured, not guessed**, using simulations.

### 7.2 Measurement Procedure (Pair-Stat Simulations)

For each pair of stats (A, B):

1. Build three archetypes (using a new `generatePairStatArchetypes` helper):
   - `Archetype_A`: baseline + ŒîA on A only.
   - `Archetype_B`: baseline + ŒîB on B only.
   - `Archetype_AB`: baseline + ŒîA on A **and** ŒîB on B.
2. Use the existing **simulation engine** to estimate win rate deltas vs baseline:
   - `ŒîWR(A)` from Archetype_A vs baseline.
   - `ŒîWR(B)` from Archetype_B vs baseline.
   - `ŒîWR(A+B)` from Archetype_AB vs baseline.
3. Compute the **expected** improvement if A and B were purely additive:

```text
expectedDelta = ŒîWR(A) + ŒîWR(B)
```

4. Compare with the **observed** improvement of the pair:

```text
synergyDelta = ŒîWR(A+B) - expectedDelta
synergyFactor S(A,B) = f(synergyDelta)
```

Where `f` is a scaling function that converts `synergyDelta` into bonus/malus points (e.g. linear scaling with clamping).

### 7.3 Data Structure (Aligning with PairSynergyMetrics)

We already have:

```ts
// src/balancing/testing/metrics.ts
interface PairSynergyMetrics {
  statA: string;
  statB: string;
  pointsPerStat: number;
  combinedWinRate: number;  // pair vs baseline
  expectedWinRate: number;  // from singles
  synergyRatio: number;     // combined / expected
  assessment: 'OP' | 'synergistic' | 'neutral' | 'weak';
}
```

Next steps (TODO):

- Implement a `PairSynergyCalculator` that:
  - Consumes single-stat sensitivity data from Phase 6.
  - Runs pair-stat simulations as described.
  - Produces `PairSynergyMetrics[]` plus a `synergyFactor` table `S(A,B)`.
- Integrate `PairSynergyMetrics` into the UI as a **separate, clearly labeled view** from the current Round-Robin matchup advantage heatmap (which is A vs B, not the (A+B) synergy).

### 7.4 Current Status

- ‚úÖ Types for pair synergy (`PairSynergyMetrics`) and a visual component (`SynergyHeatmap`) exist.
- ‚úÖ We already have infrastructure to run thousands of simulations deterministically.
- ‚ùå Archetype generation for **pair-stat builds** and synergy-specific simulations are **not implemented yet**.
- ‚ùå The current "Synergy Heatmap" view is actually a **matchup advantage heatmap** (A vs B), not the true (A+B) vs baseline synergy metric.

---

## üß∑ PHASE 8: Automatic Balancing Pipeline with Point Budgets

> Goal: use stat point costs `C(X)` and synergies `S(A,B)` to automatically keep characters, spells, bosses, etc. within a specified **point budget**.

### 8.1 Budget Model

Each entity type gets a **budget**:

- Player tank archetype: `~100` points.
- DPS archetype: `~80` points.
- Boss: `~300` points.
- Spell: `~20` points.
- Rare item: `~60` points.

Budget is a soft design input; the system enforces it automatically via cost calculations.

### 8.2 Total Cost Formula

Given a build with stats `{X_i}` and non-zero pairs `{(X_i, X_j)}`:

```text
CostTotal = Œ£_i C(X_i) + Œ£_{i<j} S(X_i, X_j)
```

Where:

- `C(X_i)` uses the **simulation-derived** point values from Phase 6.
- `S(X_i, X_j)` uses the **synergy factors** from Phase 7 (can be zero for most pairs).

### 8.3 Auto-Adjusting Builds (Nerf/Buff Loop)

For each entity (character, spell, boss):

1. Compute `CostTotal` from its current stats.
2. Compare to its budget `Budget(entityType)`.
3. If `CostTotal > Budget`:
   - Mark as **over-budget** (needs nerf or cost increase).
   - Options:
     - Reduce some stats proportionally.
     - Increase resource cost / cooldown / rarity.
4. If `CostTotal < Budget`:
   - Mark as **under-budget** (can be safely buffed).
   - Options:
     - Grant more points in the least impactful stats.
     - Improve quality-of-life effects.

This loop can be:

- **Offline**: run periodically as a developer tool to propose balance changes.
- **Online**: applied in editor when designing a new archetype/spell, giving immediate feedback.

### 8.4 Integration Points (TODO)

- Connect stat point costs and synergy factors into:
  - `ArchetypeBuilder` / character builder modules.
  - Spell/equipment definition systems.
- Expose **budget and cost information** in the UI:
  - Show `CostTotal / Budget` gauges.
  - Highlight which stats or combinations are pushing the build over the limit.

### 8.5 Current Status

- ‚úÖ We have the **simulation infrastructure** and a **stat stress-testing UI** that already gives human-readable insight (efficiency ranking, matchups, heatmaps).
- ‚ùå We **do not yet**:
  - Compute point budgets per entity type.
  - Compute `CostTotal` from stats + synergies.
  - Run an automatic nerf/buff loop.
